import React, { useState, useEffect, useRef } from "react";

import audioUtils from '../../utils/audioUtils';
import { Mic, MicOff, Play, Pause } from "lucide-react";
import socketService from "../../services/socketService";

const CommentarySection = ({ isActive = true }) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isContinuousMode, setIsContinuousMode] = useState(false);
  const [continuousRecording, setContinuousRecording] = useState(false);
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const streamRef = useRef(null);
  const continuousIntervalRef = useRef(null);

  // Check for browser support and codecs
  const isSupported = typeof navigator !== 'undefined' &&
                     navigator.mediaDevices &&
                     navigator.mediaDevices.getUserMedia &&
                     typeof MediaRecorder !== 'undefined';

  const getSupportedMimeType = () => {
    const types = [
      'audio/webm;codecs=opus',
      'audio/ogg;codecs=opus',
      'audio/webm',
      'audio/mp4',
      'audio/wav'
    ];

    for (const type of types) {
      if (MediaRecorder.isTypeSupported(type)) {
        console.log('üéôÔ∏è Using mime type:', type);
        return type;
      }
    }
    return null;
  };

  useEffect(() => {
    return () => {
      // Cleanup on unmount
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
        mediaRecorderRef.current.stop();
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      if (continuousIntervalRef.current) {
        clearInterval(continuousIntervalRef.current);
      }
    };
  }, []);

  // D·ª´ng ghi √¢m khi tab kh√¥ng active n·ªØa
  useEffect(() => {
    if (!isActive) {
      console.log('üîá [CommentarySection] Tab inactive, stopping recording');

      // D·ª´ng ghi √¢m n·∫øu ƒëang ghi
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
        mediaRecorderRef.current.stop();
        setIsRecording(false);
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }
      // D·ª´ng continuous mode
      setContinuousRecording(false);
      if (continuousIntervalRef.current) {
        clearInterval(continuousIntervalRef.current);
      }
    }
  }, [isActive]);

  const startRecording = async () => {
    if (!isSupported) {
      alert('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ ghi √¢m');
      return;
    }

    const mimeType = getSupportedMimeType();
    if (!mimeType) {
      alert('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ c√°c codec audio c·∫ßn thi·∫øt');
      return;
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100, // Standard sample rate for compatibility
          channelCount: 1, // Mono for voice
          autoGainControl: true
        }
      });

      streamRef.current = stream;

      const options = { mimeType };
      // Add bitrate if supported
      if (mimeType.includes('opus') || mimeType.includes('webm')) {
        options.audioBitsPerSecond = 64000;
      }

      const mediaRecorder = new MediaRecorder(stream, options);

      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        if (!isContinuousMode) {
          // Ch·ªâ stop stream trong normal mode
          if (streamRef.current) {
            streamRef.current.getTracks().forEach(track => track.stop());
            streamRef.current = null;
          }
        }
        processRecording();
      };

      mediaRecorder.start(100); // Collect data every 100ms
      setIsRecording(true);
      console.log('üéôÔ∏è Voice recording started with codec:', mimeType);
    } catch (error) {
      console.error('L·ªói khi b·∫Øt ƒë·∫ßu ghi √¢m:', error);
      alert('Kh√¥ng th·ªÉ truy c·∫≠p microphone. Vui l√≤ng cho ph√©p quy·ªÅn truy c·∫≠p.');
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      setIsProcessing(true);
    }
  };

  const processRecording = async () => {
    if (audioChunksRef.current.length > 0) {
      const mimeType = mediaRecorderRef.current?.mimeType || getSupportedMimeType() || 'audio/webm';
      const audioBlob = new Blob(audioChunksRef.current, {
        type: mimeType
      });

      console.log('üéôÔ∏è Voice recorded:', audioBlob.size, 'bytes');

      try {
        // G·ª≠i voice l√™n server qua socket
        await sendVoiceToServer(audioBlob);
        console.log('‚úÖ Voice sent to server successfully');
      } catch (error) {
        console.error('‚ùå Failed to send voice to server:', error);
        alert('Kh√¥ng th·ªÉ g·ª≠i voice l√™n server');
      }

      // Reset audio chunks ƒë·ªÉ chu·∫©n b·ªã cho l·∫ßn ghi ti·∫øp theo trong continuous mode
      audioChunksRef.current = [];
      setIsProcessing(false);

      // Trong continuous mode, t·ª± ƒë·ªông b·∫Øt ƒë·∫ßu ghi l·∫°i
      if (isContinuousMode && continuousRecording && streamRef.current) {
        setTimeout(() => {
          startNextContinuousChunk();
        }, 100); // Delay nh·ªè ƒë·ªÉ tr√°nh gap
      }
    } else {
      setIsProcessing(false);
    }
  };

  const sendVoiceToServer = async (audioBlob) => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        const arrayBuffer = reader.result;
        const uint8Array = new Uint8Array(arrayBuffer);

        if (socketService.socket && socketService.socket.connected) {
          // G·ª≠i voice data qua socketService
          const mimeType = mediaRecorderRef.current?.mimeType || getSupportedMimeType() || 'audio/webm';
          const success = socketService.sendRefereeVoice(
            Array.from(uint8Array),
            mimeType
          );

          if (success) {
            resolve();
          } else {
            reject(new Error('Failed to send voice through socket service'));
          }
        } else {
          reject(new Error('Socket not connected'));
        }
      };
      reader.onerror = () => reject(reader.error);
      reader.readAsArrayBuffer(audioBlob);
    });
  };

  const startContinuousRecording = async () => {
    if (!isSupported) {
      alert('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ ghi √¢m');
      return;
    }

    const mimeType = getSupportedMimeType();
    if (!mimeType) {
      alert('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ c√°c codec audio c·∫ßn thi·∫øt');
      return;
    }

    try {
      // L·∫•y stream m·ªôt l·∫ßn cho to√†n b·ªô continuous session
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100,
          channelCount: 1,
          autoGainControl: true
        }
      });

      streamRef.current = stream;
      setContinuousRecording(true);

      // B·∫Øt ƒë·∫ßu chunk ƒë·∫ßu ti√™n
      await startNextContinuousChunk();

      console.log('üéôÔ∏è Continuous recording started');
    } catch (error) {
      console.error('L·ªói khi b·∫Øt ƒë·∫ßu ghi √¢m li√™n t·ª•c:', error);
      alert('Kh√¥ng th·ªÉ truy c·∫≠p microphone. Vui l√≤ng cho ph√©p quy·ªÅn truy c·∫≠p.');
    }
  };

  const startNextContinuousChunk = async () => {
    if (!streamRef.current || !continuousRecording) return;

    const mimeType = getSupportedMimeType();
    const options = { mimeType };
    if (mimeType.includes('opus') || mimeType.includes('webm')) {
      options.audioBitsPerSecond = 64000;
    }

    const mediaRecorder = new MediaRecorder(streamRef.current, options);
    mediaRecorderRef.current = mediaRecorder;
    audioChunksRef.current = [];

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunksRef.current.push(event.data);
      }
    };

    mediaRecorder.onstop = () => {
      if (!isContinuousMode) {
        // Ch·ªâ stop stream trong normal mode
        if (streamRef.current) {
          streamRef.current.getTracks().forEach(track => track.stop());
          streamRef.current = null;
        }
      }
      processRecording();
    };

    mediaRecorder.start(100);
    setIsRecording(true);

    // T·ª± ƒë·ªông d·ª´ng sau 3 gi√¢y ƒë·ªÉ g·ª≠i chunk
    setTimeout(() => {
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
        mediaRecorderRef.current.stop();
        setIsRecording(false);
        setIsProcessing(true);
      }
    }, 3000);
  };

  const stopContinuousRecording = () => {
    setContinuousRecording(false);

    // D·ª´ng current recording
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }

    // Stop stream
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }

    console.log('üîá Continuous recording stopped');
  };

  const toggleRecording = () => {
    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  };

  const toggleContinuousMode = () => {
    if (continuousRecording) {
      stopContinuousRecording();
    } else {
      startContinuousRecording();
    }
  };

  return (
    <div className="p-4 space-y-4">
      {/* Voice Recording Button */}
      <div className="flex justify-center">
        <button
          onClick={toggleRecording}
          disabled={isProcessing || !isSupported}
          className={`
            w-20 h-20 rounded-full flex items-center justify-center transition-all duration-300 transform
            ${isRecording 
              ? 'bg-red-500 hover:bg-red-600 animate-pulse scale-110' 
              : 'bg-blue-500 hover:bg-blue-600'
            }
            ${isProcessing ? 'opacity-50 cursor-not-allowed' : 'hover:scale-105'}
            text-white shadow-lg hover:shadow-xl
            ${!isSupported ? 'bg-gray-400 cursor-not-allowed' : ''}
          `}
        >
          {isProcessing ? (
            <div className="animate-spin rounded-full h-8 w-8 border-b-2 border-white"></div>
          ) : isRecording ? (
            <MicOff size={32} />
          ) : (
            <Mic size={32} />
          )}
        </button>
      </div>

      {/* Status Text */}
      <div className="text-center">
        {isProcessing && (
          <p className="text-blue-600 font-medium">ƒêang x·ª≠ l√Ω...</p>
        )}
        {isRecording && !isProcessing && (
          <p className="text-red-600 font-medium animate-pulse">‚óè ƒêang ghi √¢m...</p>
        )}
        {!isRecording && !isProcessing && (
          <p className="text-gray-600">·∫§n mic ƒë·ªÉ b·∫Øt ƒë·∫ßu b√¨nh lu·∫≠n</p>
        )}
        {!isSupported && (
          <p className="text-red-600">Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ ghi √¢m</p>
        )}
      </div>
    </div>
  );
};

export default CommentarySection;
