import React, { useState, useEffect, useRef } from "react";
import { Mic, MicOff } from "lucide-react";
import socketService from "../../services/socketService";

const CommentarySection = ({ isActive = true }) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const mediaRecorderRef = useRef(null);
  const streamRef = useRef(null);
  const continuousTimeoutRef = useRef(null);
  const audioChunksRef = useRef([]);
  
  // REF ƒë·ªÉ track real-time state
  const isRecordingRef = useRef(false);

  // Sync ref v·ªõi state
  useEffect(() => {
    isRecordingRef.current = isRecording;
  }, [isRecording]);

  // Check for browser support and codecs
  const isSupported = typeof navigator !== 'undefined' &&
                     navigator.mediaDevices &&
                     navigator.mediaDevices.getUserMedia &&
                     typeof MediaRecorder !== 'undefined';

  const getSupportedMimeType = () => {
    const types = [
      'audio/webm;codecs=opus',
      'audio/ogg;codecs=opus',
      'audio/webm',
      'audio/mp4',
      'audio/wav'
    ];

    for (const type of types) {
      if (MediaRecorder.isTypeSupported(type)) {
        console.log('üéôÔ∏è Using mime type:', type);
        return type;
      }
    }
    return null;
  };

  // Test if browser can play the recorded format
  const canPlayFormat = (mimeType) => {
    const audio = document.createElement('audio');
    return audio.canPlayType(mimeType) !== '';
  };

  useEffect(() => {
    return () => {
      // Cleanup on unmount
      stopAllRecording();
    };
  }, []);

  // D·ª´ng ghi √¢m khi tab kh√¥ng active n·ªØa
  useEffect(() => {
    if (!isActive) {
      console.log('üîá [CommentarySection] Tab inactive, stopping recording');
      stopAllRecording();
    }
  }, [isActive]);

  const stopAllRecording = () => {
    // D·ª´ng ghi √¢m hi·ªán t·∫°i
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
    }
    
    // D·ª´ng stream
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    
    // Clear timeout
    if (continuousTimeoutRef.current) {
      clearTimeout(continuousTimeoutRef.current);
      continuousTimeoutRef.current = null;
    }
    
    // Reset states
    setIsRecording(false);
    setIsProcessing(false);
    audioChunksRef.current = [];
  };

  const sendAccumulatedChunks = () => {
    if (audioChunksRef.current.length === 0) {
      console.log('‚ö†Ô∏è No chunks to send');
      return;
    }

    const mimeType = mediaRecorderRef.current?.mimeType || getSupportedMimeType() || 'audio/webm';
    const audioBlob = new Blob(audioChunksRef.current, { type: mimeType });

    console.log('üì° Sending accumulated chunks:', {
      chunksCount: audioChunksRef.current.length,
      totalSize: audioBlob.size,
      mimeType: mimeType
    });

    // Ki·ªÉm tra n·∫øu blob qu√° nh·ªè
    if (audioBlob.size < 1000) { // < 1KB
      console.warn('‚ö†Ô∏è Audio blob too small, might be invalid:', audioBlob.size, 'bytes');
      // V·∫´n th·ª≠ g·ª≠i, nh∆∞ng c·∫£nh b√°o
    }

    // Reset chunks array ngay sau khi t·∫°o blob
    audioChunksRef.current = [];
    
    // G·ª≠i ngay l·∫≠p t·ª©c
    sendVoiceToServer(audioBlob).then(() => {
      console.log('‚úÖ Accumulated chunks sent successfully');
    }).catch(error => {
      console.error('‚ùå Failed to send accumulated chunks:', error);
    });
  };

  const createMediaRecorder = async (stream, mimeType) => {
    const options = { 
      mimeType,
      audioBitsPerSecond: 128000 // TƒÉng bitrate ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng
    };

    const mediaRecorder = new MediaRecorder(stream, options);
    mediaRecorderRef.current = mediaRecorder;

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        console.log('üì• Data chunk received:', event.data.size, 'bytes');
        // T√≠ch l≈©y chunks thay v√¨ g·ª≠i ngay
        audioChunksRef.current.push(event.data);
        console.log('üì¶ Total chunks accumulated:', audioChunksRef.current.length);
      }
    };

    mediaRecorder.onstop = () => {
      console.log('üéôÔ∏è MediaRecorder stopped');
      
      // G·ª≠i t·∫•t c·∫£ chunks ƒë√£ t√≠ch l≈©y
      if (audioChunksRef.current.length > 0) {
        sendAccumulatedChunks();
      }
      
      if (isRecordingRef.current) {
        // N·∫øu v·∫´n ƒëang trong ch·∫ø ƒë·ªô recording, restart ngay l·∫≠p t·ª©c
        scheduleNextChunk();
      }
    };

    mediaRecorder.onstart = () => {
      console.log('üéôÔ∏è MediaRecorder started');
      audioChunksRef.current = []; // Reset chunks khi b·∫Øt ƒë·∫ßu
    };

    // B·∫Øt ƒë·∫ßu ghi v·ªõi timeslice 500ms (tƒÉng t·ª´ 100ms)
    console.log('üéôÔ∏è Starting MediaRecorder with 500ms chunks');
    mediaRecorder.start(500); // 500ms chunks ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªß data
    setIsRecording(true);

    // T·ª± ƒë·ªông restart sau 2 gi√¢y
    continuousTimeoutRef.current = setTimeout(() => {
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        console.log('üîÑ Auto-restarting recording (500ms -> send)');
        mediaRecorderRef.current.stop(); // N√†y s·∫Ω trigger onstop -> g·ª≠i chunks
      }
    }, 2000);
  };

  const scheduleNextChunk = () => {
    if (!isRecordingRef.current) {
      console.log('‚èπÔ∏è Recording stopped, not scheduling next chunk');
      return;
    }

    console.log('üîÑ Scheduling next chunk');
    continuousTimeoutRef.current = setTimeout(() => {
      if (isRecordingRef.current && streamRef.current && streamRef.current.active) {
        startNextChunk();
      }
    }, 100); // Delay ng·∫Øn ƒë·ªÉ tr√°nh gap
  };

  const startNextChunk = async () => {
    if (!streamRef.current || !streamRef.current.active || !isRecordingRef.current) {
      console.log('‚ö†Ô∏è Cannot start next chunk - stream inactive or recording stopped');
      return;
    }

    console.log('üéôÔ∏è Starting next chunk');
    const mimeType = getSupportedMimeType();
    await createMediaRecorder(streamRef.current, mimeType);
  };

  const startRecording = async () => {
    if (!isSupported) {
      alert('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ ghi √¢m');
      return;
    }

    const mimeType = getSupportedMimeType();
    if (!mimeType) {
      alert('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ c√°c codec audio c·∫ßn thi·∫øt');
      return;
    }

    // Test if browser can play this format
    if (!canPlayFormat(mimeType)) {
      console.warn('‚ö†Ô∏è Browser may not be able to play recorded format:', mimeType);
    }

    try {
      setIsProcessing(true);
      
      // T·∫°o stream m·ªõi
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 48000, // TƒÉng sample rate
          channelCount: 1,
          autoGainControl: true
        }
      });
      streamRef.current = stream;

      await createMediaRecorder(stream, mimeType);
      
      setIsProcessing(false);
      console.log('üéôÔ∏è Continuous recording started with format:', mimeType);
    } catch (error) {
      console.error('L·ªói khi b·∫Øt ƒë·∫ßu ghi √¢m:', error);
      alert('Kh√¥ng th·ªÉ truy c·∫≠p microphone. Vui l√≤ng cho ph√©p quy·ªÅn truy c·∫≠p.');
      setIsProcessing(false);
    }
  };

  const stopRecording = () => {
    console.log('üîá Stopping continuous recording');
    setIsRecording(false);
    
    if (continuousTimeoutRef.current) {
      clearTimeout(continuousTimeoutRef.current);
      continuousTimeoutRef.current = null;
    }

    // D·ª´ng current recording v√† g·ª≠i chunks cu·ªëi c√πng
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop(); // N√†y s·∫Ω trigger g·ª≠i chunks cu·ªëi
    }

    // D·ª´ng stream
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
  };

  const sendVoiceToServer = async (audioBlob) => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        const arrayBuffer = reader.result;
        const uint8Array = new Uint8Array(arrayBuffer);

        if (socketService.socket && socketService.socket.connected) {
          const mimeType = mediaRecorderRef.current?.mimeType || getSupportedMimeType() || 'audio/webm';
          const success = socketService.sendRefereeVoice(
            Array.from(uint8Array),
            mimeType
          );

          if (success) {
            resolve();
          } else {
            reject(new Error('Failed to send voice through socket service'));
          }
        } else {
          reject(new Error('Socket not connected'));
        }
      };
      reader.onerror = () => reject(reader.error);
      reader.readAsArrayBuffer(audioBlob);
    });
  };

  const toggleRecording = () => {
    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  };

  return (
    <div className="p-4 space-y-4">
      {/* Voice Recording Button */}
      <div className="flex justify-center">
        <button
          onClick={toggleRecording}
          disabled={isProcessing || !isSupported}
          className={`
            w-20 h-20 rounded-full flex items-center justify-center transition-all duration-300 transform
            ${isRecording
              ? 'bg-red-500 hover:bg-red-600 animate-pulse scale-110'
              : 'bg-blue-500 hover:bg-blue-600'
            }
            ${isProcessing ? 'opacity-50 cursor-not-allowed' : 'hover:scale-105'}
            text-white shadow-lg hover:shadow-xl
            ${!isSupported ? 'bg-gray-400 cursor-not-allowed' : ''}
          `}
        >
          {isProcessing ? (
            <div className="animate-spin rounded-full h-8 w-8 border-b-2 border-white"></div>
          ) : isRecording ? (
            <MicOff size={32} />
          ) : (
            <Mic size={32} />
          )}
        </button>
      </div>

      {/* Status Text */}
      <div className="text-center">
        {isProcessing && (
          <p className="text-blue-600 font-medium">ƒêang kh·ªüi t·∫°o...</p>
        )}
        {isRecording && !isProcessing && (
          <p className="text-red-600 font-medium animate-pulse">
            üî¥ ƒêang thu √¢m
          </p>
        )}
        {!isRecording && !isProcessing && (
          <p className="text-gray-600">
            ·∫§n mic ƒë·ªÉ b·∫Øt ƒë·∫ßu b√¨nh lu·∫≠n li√™n t·ª•c
          </p>
        )}
        {!isSupported && (
          <p className="text-red-600">Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ ghi √¢m</p>
        )}
      </div>

    </div>
  );
};

export default CommentarySection;