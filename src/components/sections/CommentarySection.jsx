import React, { useState, useEffect, useRef } from "react";
import { Mic, MicOff } from "lucide-react";
import socketService from "../../services/socketService";

const CommentarySection = ({ isActive = true }) => {
  const [isStreaming, setIsStreaming] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const audioContextRef = useRef(null);
  const mediaStreamSourceRef = useRef(null);
  const scriptNodeRef = useRef(null);
  const streamRef = useRef(null);
  const isStreamingRef = useRef(false); // Add ref to track streaming state

  const isSupported =
    typeof navigator !== "undefined" &&
    navigator.mediaDevices &&
    navigator.mediaDevices.getUserMedia &&
    typeof AudioContext !== "undefined";

  useEffect(() => {
    return () => {
      stopAllStreaming();
    };
  }, []);

  useEffect(() => {
    if (!isActive) {
      console.log("üîá [CommentarySection] Tab inactive, stopping streaming");
      stopAllStreaming();
    }
  }, [isActive]);

  // Update ref when state changes
  useEffect(() => {
    isStreamingRef.current = isStreaming;
  }, [isStreaming]);

  const stopAllStreaming = () => {
    console.log("üîá [stopAllStreaming] Cleaning up all audio resources");
    
    // Stop script processor
    if (scriptNodeRef.current) {
      try {
        scriptNodeRef.current.disconnect();
        console.log("‚úÖ Script node disconnected");
      } catch (e) {
        console.warn("‚ö†Ô∏è Error disconnecting script node:", e);
      }
      scriptNodeRef.current = null;
    }

    // Disconnect media stream source
    if (mediaStreamSourceRef.current) {
      try {
        mediaStreamSourceRef.current.disconnect();
        console.log("‚úÖ Media stream source disconnected");
      } catch (e) {
        console.warn("‚ö†Ô∏è Error disconnecting media stream source:", e);
      }
      mediaStreamSourceRef.current = null;
    }

    // Close audio context
    if (audioContextRef.current && audioContextRef.current.state !== "closed") {
      try {
        audioContextRef.current.close();
        console.log("‚úÖ Audio context closed");
      } catch (e) {
        console.warn("‚ö†Ô∏è Error closing audio context:", e);
      }
      audioContextRef.current = null;
    }

    // Stop media stream
    if (streamRef.current) {
      streamRef.current.getTracks().forEach((track) => {
        track.stop();
        console.log("‚úÖ Media track stopped");
      });
      streamRef.current = null;
    }

    setIsStreaming(false);
    setIsProcessing(false);
  };

  const setupAudioStream = async (stream) => {
    try {
      console.log("üéôÔ∏è [setupAudioStream] Setting up audio stream...");
      
      // Create audio context with low latency
      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({
        latencyHint: 'interactive',
        sampleRate: 44100
      });

      // Resume context if suspended
      if (audioContextRef.current.state === 'suspended') {
        await audioContextRef.current.resume();
        console.log("üéôÔ∏è Audio context resumed");
      }

      // Create media stream source
      mediaStreamSourceRef.current = audioContextRef.current.createMediaStreamSource(stream);

      console.log("‚úÖ Audio stream setup completed");
      console.log("üìä Audio context state:", audioContextRef.current.state);
      console.log("üìä Sample rate:", audioContextRef.current.sampleRate);
      
      return true;
    } catch (error) {
      console.error("‚ùå Error setting up audio stream:", error);
      return false;
    }
  };

  const startStreaming = () => {
    console.log("üéôÔ∏è [startStreaming] Starting audio streaming...");
    
    if (!audioContextRef.current || !mediaStreamSourceRef.current) {
      console.error("‚ùå Audio context or media stream source not available");
      console.log("üîç Audio context:", audioContextRef.current);
      console.log("üîç Media stream source:", mediaStreamSourceRef.current);
      return;
    }

    // Check socket connection before starting
    if (!socketService || !socketService.socket) {
      console.error("‚ùå SocketService or socket not available");
      console.log("üîç SocketService:", socketService);
      return;
    }

    if (!socketService.socket.connected) {
      console.error("‚ùå Socket not connected");
      console.log("üîç Socket state:", socketService.socket.connected);
      return;
    }

    try {
      const bufferSize = 2048;
      scriptNodeRef.current = audioContextRef.current.createScriptProcessor(bufferSize, 1, 1);
      console.log("‚úÖ Script processor created with buffer size:", bufferSize);

      scriptNodeRef.current.onaudioprocess = (audioProcessingEvent) => {
        // Use ref instead of state to avoid stale closure
        if (!isStreamingRef.current) {
          console.log("‚èπÔ∏è Not streaming, skipping audio data");
          return;
        }

        if (!scriptNodeRef.current) {
          console.log("‚èπÔ∏è Script node is null, skipping audio data");
          return;
        }

        try {
          const inputBuffer = audioProcessingEvent.inputBuffer;
          const audioData = inputBuffer.getChannelData(0);
          
          // Check for non-zero audio data
          const hasSound = Array.from(audioData).some(sample => Math.abs(sample) > 0.001);
          if (hasSound) {
            console.log('üîä Audio data captured with sound:', audioData.length, 'samples');
          }
          
          // Send Float32Array to server
          if (socketService.socket && socketService.socket.connected) {
            if (typeof socketService.sendRefereeVoiceRealtime === 'function') {
              socketService.sendRefereeVoiceRealtime(Array.from(audioData));
              if (hasSound) {
                console.log('üì§ Audio data sent to server');
              }
            } else {
              console.error('‚ùå sendRefereeVoiceRealtime is not a function');
              console.log('üîç Available methods:', Object.keys(socketService));
            }
          } else {
            console.log('‚ùå Socket not connected');
          }
        } catch (error) {
          console.error('‚ùå Error in audio processing:', error);
        }
      };

      // Connect nodes
      mediaStreamSourceRef.current.connect(scriptNodeRef.current);
      scriptNodeRef.current.connect(audioContextRef.current.destination);

      console.log("‚úÖ Audio nodes connected successfully");
      console.log("üìä Audio context state:", audioContextRef.current.state);
      
      setIsStreaming(true);
      console.log("üéôÔ∏è Real-time audio streaming started");
      
    } catch (error) {
      console.error("‚ùå Error starting streaming:", error);
      // Clean up on error
      if (scriptNodeRef.current) {
        try {
          scriptNodeRef.current.disconnect();
        } catch (e) {
          console.warn("‚ö†Ô∏è Error cleaning up script node:", e);
        }
        scriptNodeRef.current = null;
      }
    }
  };

  const stopStreaming = () => {
    console.log("üîá [stopStreaming] Stopping real-time streaming");

    if (scriptNodeRef.current) {
      try {
        scriptNodeRef.current.disconnect();
        console.log("‚úÖ Script node disconnected");
      } catch (e) {
        console.warn("‚ö†Ô∏è Error disconnecting script node:", e);
      }
      scriptNodeRef.current = null;
    }

    setIsStreaming(false);
  };

  const startMicrophone = async () => {
    if (!isSupported) {
      alert("Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ Web Audio API");
      return;
    }

    try {
      setIsProcessing(true);
      console.log("üéôÔ∏è [startMicrophone] Requesting microphone access...");
      
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100,
          channelCount: 1,
          autoGainControl: true,
        },
      });

      console.log("‚úÖ Microphone access granted");
      console.log("üìä Stream tracks:", stream.getTracks().length);
      
      streamRef.current = stream;
      const success = await setupAudioStream(stream);

      if (success) {
        // Small delay to ensure everything is set up
        setTimeout(() => {
          startStreaming();
          setIsProcessing(false);
          console.log("üéôÔ∏è Microphone and streaming initialized successfully");
        }, 100);
      } else {
        setIsProcessing(false);
        alert("Kh√¥ng th·ªÉ kh·ªüi t·∫°o audio context");
      }
    } catch (error) {
      console.error("‚ùå Error starting microphone:", error);
      alert("Kh√¥ng th·ªÉ truy c·∫≠p microphone. Vui l√≤ng cho ph√©p quy·ªÅn truy c·∫≠p.");
      setIsProcessing(false);
    }
  };

  const stopMicrophone = () => {
    console.log("üîá [stopMicrophone] Stopping microphone");
    stopStreaming();

    if (streamRef.current) {
      streamRef.current.getTracks().forEach((track) => {
        track.stop();
        console.log("‚úÖ Media track stopped");
      });
      streamRef.current = null;
    }
  };

  const toggleMicrophone = () => {
    console.log("üîÑ [toggleMicrophone] Current streaming state:", isStreaming);
    if (isStreaming) {
      stopMicrophone();
    } else {
      startMicrophone();
    }
  };

  // Debug info
  useEffect(() => {
    console.log("üîç [Debug] Component state:");
    console.log("- isStreaming:", isStreaming);
    console.log("- isProcessing:", isProcessing);
    console.log("- isActive:", isActive);
    console.log("- socketService:", socketService);
    console.log("- socket connected:", socketService?.socket?.connected);
  }, [isStreaming, isProcessing, isActive]);

  return (
    <div className="p-4 space-y-4">
      <div className="flex justify-center">
        <button
          onClick={toggleMicrophone}
          disabled={isProcessing || !isSupported}
          className={`
            w-20 h-20 rounded-full flex items-center justify-center transition-all duration-300 transform
            ${isStreaming
              ? "bg-red-500 hover:bg-red-600 animate-pulse scale-110"
              : "bg-blue-500 hover:bg-blue-600"}
            ${isProcessing ? "opacity-50 cursor-not-allowed" : "hover:scale-105"}
            text-white shadow-lg hover:shadow-xl
            ${!isSupported ? "bg-gray-400 cursor-not-allowed" : ""}
          `}
        >
          {isProcessing ? (
            <div className="animate-spin rounded-full h-8 w-8 border-b-2 border-white"></div>
          ) : isStreaming ? (
            <MicOff size={32} />
          ) : (
            <Mic size={32} />
          )}
        </button>
      </div>
      <div className="text-center">
        {isProcessing && (
          <p className="text-blue-600 font-medium">ƒêang kh·ªüi t·∫°o...</p>
        )}
        {isStreaming && !isProcessing && (
          <p className="text-red-600 font-medium animate-pulse">
            üî¥ ƒêang ph√°t tr·ª±c ti·∫øp
          </p>
        )}
        {!isStreaming && !isProcessing && (
          <p className="text-gray-600">·∫§n mic ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√°t tr·ª±c ti·∫øp</p>
        )}
        {!isSupported && (
          <p className="text-red-600">Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ Web Audio API</p>
        )}
      </div>
    </div>
  );
};

export default CommentarySection;